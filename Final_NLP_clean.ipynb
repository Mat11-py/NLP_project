{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1ExChMXUKTqoy1lUXRQ2vBhFCWiVsAj06",
      "authorship_tag": "ABX9TyM+QbNvTXHP6x9gerpNnEfz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mat11-py/NLP_project/blob/main/Final_NLP_clean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PROYECTO FINAL\n",
        "El desafío a realizarse consiste en realizar un estudios exploratorio de 3 modelos en la tarea de clasificación de emociones (https://github.com/fmplaza/EmoEvent/tree/master/splits). Este dataset contiene 8409 tweets anotados con una de las siguientes categorías: anger, sadness, joy, disgust, fear, surprise, offensive, other. Además, los tweets están relacionados a eventos particulares encontrados en Twitter."
      ],
      "metadata": {
        "id": "lLR0s4R4sHJ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. IMPORTAR O DESCARGAR LIBRERÍAS"
      ],
      "metadata": {
        "id": "jstafnRj-tOh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oylCb4gzsEZZ"
      },
      "outputs": [],
      "source": [
        "!pip install transformers==4.47.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "eOZLhnOwSTsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import string\n",
        "from datasets import Dataset, ClassLabel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, GRU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from transformers import AdamW, get_scheduler, AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, logging, TrainingArguments"
      ],
      "metadata": {
        "id": "TnCEIsg7LJUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. CARGA DE DATOS"
      ],
      "metadata": {
        "id": "U71MJkqm-y5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/PhawAi/NLP/EmoEvent-master/emoevent_en.csv\""
      ],
      "metadata": {
        "id": "BvHXm7_RzupO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(path,sep=\"\\t\")"
      ],
      "metadata": {
        "id": "mSkbBIhxz-li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. PREPROCESAMIENTO\n"
      ],
      "metadata": {
        "id": "Hzkuz7dp-1iZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "3CiMu4rI1Fjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "cgKRUuqy1HCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "FlqVahSc-gUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe(include=\"all\")"
      ],
      "metadata": {
        "id": "r7QMSttf-jLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"emotion\"].unique()"
      ],
      "metadata": {
        "id": "uP8Fpp-9-Udy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ea = df.emotion.value_counts().reset_index() # ea -> emotion analysis\n",
        "ea"
      ],
      "metadata": {
        "id": "-OJN4Mbg-ePE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ea.columns"
      ],
      "metadata": {
        "id": "9CZ1QHvbACxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.pie(ea['count'], labels=ea['emotion'], autopct=\"%1.1f%%\")\n",
        "plt.title(\"Porcentaje de emociones\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GIv3iVsx_YHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oa = df.offensive.value_counts().reset_index() # oa -> offensive analysis\n",
        "oa"
      ],
      "metadata": {
        "id": "cD2_2OVxB_6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.pie(oa['count'], labels=oa['offensive'], autopct=\"%1.1f%%\")\n",
        "plt.title(\"Porcentaje de tweets ofensivos\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4m2yMrLfCMTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "UKQkTQWU__ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def limpiar_texto(texto):\n",
        "    \"\"\"\n",
        "    Limpieza de los tweets\n",
        "    \"\"\"\n",
        "    texto = texto.lower()  # todo minúscula\n",
        "    texto = re.sub(r'http\\S+', '', texto)  # quitar URLs\n",
        "    texto = re.sub(r'@\\w+', '', texto)  # quitar menciones\n",
        "    texto = re.sub(r'#\\w+', '', texto)  # quitar hashtags\n",
        "    texto = re.sub(r'\\d+', '', texto)  # quitar números\n",
        "    texto = texto.translate(str.maketrans('', '', string.punctuation))  # quitar puntuación\n",
        "    texto = re.sub(r'\\s+', ' ', texto).strip()  # quitar espacios extras\n",
        "    return texto"
      ],
      "metadata": {
        "id": "hAVtAjEtA-PK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['clean_tweet'] = df['tweet'].apply(limpiar_texto)"
      ],
      "metadata": {
        "id": "8PyuLs5eBuDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "ZKoDqMc_B36p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder() #objeto codificador de etiquetas\n",
        "\n",
        "\n",
        "df['emotion_encoded'] = le.fit_transform(df['emotion'])#transformación\n",
        "\n",
        "# mapeo de clases\n",
        "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
        "print(\"Label mapping:\", label_mapping)"
      ],
      "metadata": {
        "id": "N-qtE4bbB48Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "5dRYC9vFGCNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "jPMwyezYGeES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape[0]"
      ],
      "metadata": {
        "id": "EHzLMWT3G7wB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['clean_tweet']\n",
        "y = df['emotion_encoded']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    stratify=y, #compensación de equitas\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Tamaño de los conjuntos\n",
        "print(\"Tamaño del conjunto de entrenamiento:\", len(X_train))\n",
        "print(\"Tamaño del conjunto de prueba:\", len(X_test))\n"
      ],
      "metadata": {
        "id": "e6DnqUsJGDRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. MODELAMIENTO"
      ],
      "metadata": {
        "id": "7VrNB_m2J_KR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualizacion_resultados(history,n):\n",
        "  \"\"\"\n",
        "  visualización de la evaluación según accuracy\n",
        "  \"\"\"\n",
        "  epochs = [i for i in range(n)]\n",
        "  fig, ax = plt.subplots(1,2)\n",
        "  train_acc = history.history[\"accuracy\"]\n",
        "  train_loss = history.history[\"loss\"]\n",
        "  val_acc = history.history[\"val_accuracy\"]\n",
        "  val_loss = history.history[\"val_loss\"]\n",
        "  fig.set_size_inches(16,9)\n",
        "\n",
        "  ax[0].plot(epochs, train_acc, \"go-\",label = \"Entrenamiento accuracy\")\n",
        "  ax[0].plot(epochs, val_acc, \"ro-\",label = \"Validación accuracy\")\n",
        "  ax[0].set_title(\"Entrenamiento y validación accuracy\")\n",
        "  ax[0].legend()\n",
        "  ax[0].set_xlabel(\"Epochs\")\n",
        "  ax[0].set_ylabel(\"Accuracy\")\n",
        "\n",
        "  ax[1].plot(epochs, train_loss, \"go-\",label = \"Entrenamiento loss\")\n",
        "  ax[1].plot(epochs, val_loss, \"ro-\",label = \"Validación loss\")\n",
        "  ax[1].set_title(\"Entrenamiento y validación loss\")\n",
        "  ax[1].legend()\n",
        "  ax[1].set_xlabel(\"Epochs\")\n",
        "  ax[1].set_ylabel(\"Loss\")\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "qkHWcwHigxUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 LSTM\n",
        "LSTM es una arquitectura de red neuronal recurrente (RNN) diseñada para manejar secuencias y capturar dependencias a largo plazo en texto. En el caso de clasificación de emociones en tweets, LSTM permite analizar la estructura secuencial de las palabras y detectar patrones emocionales a lo largo del mensaje, incluso si hay palabras clave separadas por otras menos relevantes."
      ],
      "metadata": {
        "id": "6nzuH8WuKC0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hiperparámetros\n",
        "vocab_size = 10000  # número máximo de palabras a considerar\n",
        "max_length = 100     # longitud máxima del tweet\n",
        "oov_token = \"<OOV>\" # palabras fuera de vocabulario\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)\n",
        "\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# Convertir textos a secuencias de enteros\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "# Rellenar las secuencias para que todas tengan la misma longitud\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_length, padding='post', truncating='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "print(\"Texto original:\", X_train.iloc[0])\n",
        "print(\"Secuencia:\", X_train_seq[0])\n",
        "print(\"Secuencia padded:\", X_train_pad[0])\n"
      ],
      "metadata": {
        "id": "uz2EOKFAJHYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(df['emotion_encoded'].unique()) #Clases\n",
        "\n",
        "# Codificación one-hot\n",
        "y_train_cat = to_categorical(y_train, num_classes=num_classes)\n",
        "y_test_cat = to_categorical(y_test, num_classes=num_classes)\n"
      ],
      "metadata": {
        "id": "3t0ik8JDJrXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=128, input_length=max_length),\n",
        "    Bidirectional(LSTM(150, return_sequences=False)),\n",
        "    #Dense(10000, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "G2ONeQkOJ2Vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train_pad,\n",
        "    y_train_cat,\n",
        "    validation_split=0.1,\n",
        "    epochs=15,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "h3warh9bKP7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualizacion_resultados(history,15)"
      ],
      "metadata": {
        "id": "tRrqFw0yg3sA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicciones LSTM\n",
        "y_pred_probs = model.predict(X_test_pad)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "y_true = np.argmax(y_test_cat, axis=1)\n",
        "\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=le.classes_))"
      ],
      "metadata": {
        "id": "cJVUWWneKzNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Real')\n",
        "plt.title('Matriz de Confusión - LSTM')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "S4a77GWOLATI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.2 GRU\n",
        "GRU es una variante más eficiente y simplificada de LSTM. Para la clasificación de emociones, GRU puede capturar patrones secuenciales de manera similar, pero con menor costo computacional, lo que lo hace atractivo cuando se dispone de recursos limitados o se requiere un entrenamiento más rápido."
      ],
      "metadata": {
        "id": "pdUUL4hZek5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_gru = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=128, input_length=max_length),\n",
        "    GRU(150, return_sequences=False),\n",
        "    #Dense(64, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model_gru.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "FB2jn02uSdcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_gru = model_gru.fit(\n",
        "    X_train_pad,\n",
        "    y_train_cat,\n",
        "    validation_split=0.1,\n",
        "    epochs=15,\n",
        "    batch_size=32,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "gApux647e8X9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualizacion_resultados(history_gru,15)"
      ],
      "metadata": {
        "id": "TN-0CbIeg8gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicciones gru\n",
        "y_pred_probs = model_gru.predict(X_test_pad)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "y_true = np.argmax(y_test_cat, axis=1)\n",
        "\n",
        "\n",
        "print(classification_report(y_true, y_pred, target_names=le.classes_))"
      ],
      "metadata": {
        "id": "c770Ru1Xffr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Real')\n",
        "plt.title('Matriz de Confusión - GRU')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u8OuBbfjfvUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.3 BERT - FINE TUNING\n",
        "BERT es un modelo de lenguaje preentrenado basado en Transformers que entiende el contexto completo de una palabra al considerar tanto la izquierda como la derecha (bidireccionalidad). Para la clasificación de emociones en tweets, BERT es altamente efectivo porque ya ha sido entrenado con grandes corpus de texto, lo que le permite comprender matices emocionales, sinónimos, ambigüedad semántica, y expresiones propias del lenguaje natural."
      ],
      "metadata": {
        "id": "GV4OCQyJJlJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_Bert = df[['clean_tweet', 'emotion_encoded']]\n",
        "df_Bert.head()"
      ],
      "metadata": {
        "id": "zl4g-yhSRINz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapeo de las clases\n",
        "label_names = df_Bert['emotion_encoded'].unique().tolist()\n",
        "label_names.sort()  # Asegura el orden de los índices"
      ],
      "metadata": {
        "id": "xZosFPMeTCB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Dataset.from_pandas(df_Bert)"
      ],
      "metadata": {
        "id": "Y1Xu-vWvSD7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir la columna de etiquetas a ClassLabel\n",
        "dataset = dataset.cast_column(\"emotion_encoded\", ClassLabel(names=[str(i) for i in label_names]))\n",
        "\n",
        "dataset = dataset.train_test_split(test_size=0.2, stratify_by_column=\"emotion_encoded\", seed=42)\n"
      ],
      "metadata": {
        "id": "XdaN9-ipTHOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "1kLcfO6XSeO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizador\n",
        "model_checkpoint = \"bert-base-uncased\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "nNieHJGyM6NR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(example):\n",
        "  \"\"\"\n",
        "  tokenizador en el dataset\n",
        "  \"\"\"\n",
        "  return tokenizer(\n",
        "        example[\"clean_tweet\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=128\n",
        "        )"
      ],
      "metadata": {
        "id": "_xAnBm0yTYyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "PqMTuP6fVqM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset['train'][0]"
      ],
      "metadata": {
        "id": "3JFJNhSLVv0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels = tokenized_dataset['train'].features['emotion_encoded'].num_classes\n",
        "num_labels"
      ],
      "metadata": {
        "id": "NldD_gYPV3WU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=num_labels\n",
        ")"
      ],
      "metadata": {
        "id": "0qyv8IIUWOC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.config"
      ],
      "metadata": {
        "id": "yz1C0ZdcWbXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset"
      ],
      "metadata": {
        "id": "MyguSdtcXnNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eliminar columnas innecesarias\n",
        "tokenized_dataset = tokenized_dataset.remove_columns(['clean_tweet','token_type_ids'])  # Ajusta si es necesario\n",
        "\n",
        "# Establecer el formato para PyTorch\n",
        "tokenized_dataset.set_format(\"torch\")"
      ],
      "metadata": {
        "id": "QsiZcig5XZgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = logits.argmax(axis=-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='macro')\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "    }"
      ],
      "metadata": {
        "id": "iLNh3fB4YRGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./bert-emotion\",         # carpeta de salida\n",
        "    evaluation_strategy=\"epoch\",         # evalúa al final de cada época\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    report_to=\"none\",\n",
        ")"
      ],
      "metadata": {
        "id": "dB3NbZr0YsGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Entrenar\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "LoZCBYn6YwwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicciones\n",
        "predictions = trainer.predict(tokenized_dataset[\"test\"])\n",
        "y_pred = np.argmax(predictions.predictions, axis=1)\n",
        "y_true = predictions.label_ids\n",
        "\n"
      ],
      "metadata": {
        "id": "Q83kwbWkY3XC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reporte de clasificación\n",
        "print(classification_report(y_true, y_pred, target_names=tokenized_dataset['train'].features['labels'].names))\n",
        "\n"
      ],
      "metadata": {
        "id": "f8_ZDUZ2Y5qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matriz de confusión\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=tokenized_dataset['train'].features['labels'].names,\n",
        "            yticklabels=tokenized_dataset['train'].features['labels'].names)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix - BERT\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NafUgL3lY64z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UtyoqhnhLNPY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}